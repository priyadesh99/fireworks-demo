{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "BpS2R90Pb0U5",
        "outputId": "d2cce6ef-08a6-47f3-f424-62e23976adb1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: fastapi in /usr/local/lib/python3.12/dist-packages (0.116.1)\n",
            "Requirement already satisfied: uvicorn in /usr/local/lib/python3.12/dist-packages (0.35.0)\n",
            "Requirement already satisfied: nest_asyncio in /usr/local/lib/python3.12/dist-packages (1.6.0)\n",
            "Collecting pyngrok\n",
            "  Downloading pyngrok-7.3.0-py3-none-any.whl.metadata (8.1 kB)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (2.32.4)\n",
            "Requirement already satisfied: starlette<0.48.0,>=0.40.0 in /usr/local/lib/python3.12/dist-packages (from fastapi) (0.47.3)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,!=2.0.0,!=2.0.1,!=2.1.0,<3.0.0,>=1.7.4 in /usr/local/lib/python3.12/dist-packages (from fastapi) (2.11.7)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.12/dist-packages (from fastapi) (4.15.0)\n",
            "Requirement already satisfied: click>=7.0 in /usr/local/lib/python3.12/dist-packages (from uvicorn) (8.2.1)\n",
            "Requirement already satisfied: h11>=0.8 in /usr/local/lib/python3.12/dist-packages (from uvicorn) (0.16.0)\n",
            "Requirement already satisfied: PyYAML>=5.1 in /usr/local/lib/python3.12/dist-packages (from pyngrok) (6.0.2)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests) (3.4.3)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests) (2025.8.3)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic!=1.8,!=1.8.1,!=2.0.0,!=2.0.1,!=2.1.0,<3.0.0,>=1.7.4->fastapi) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.12/dist-packages (from pydantic!=1.8,!=1.8.1,!=2.0.0,!=2.0.1,!=2.1.0,<3.0.0,>=1.7.4->fastapi) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from pydantic!=1.8,!=1.8.1,!=2.0.0,!=2.0.1,!=2.1.0,<3.0.0,>=1.7.4->fastapi) (0.4.1)\n",
            "Requirement already satisfied: anyio<5,>=3.6.2 in /usr/local/lib/python3.12/dist-packages (from starlette<0.48.0,>=0.40.0->fastapi) (4.10.0)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.12/dist-packages (from anyio<5,>=3.6.2->starlette<0.48.0,>=0.40.0->fastapi) (1.3.1)\n",
            "Downloading pyngrok-7.3.0-py3-none-any.whl (25 kB)\n",
            "Installing collected packages: pyngrok\n",
            "Successfully installed pyngrok-7.3.0\n"
          ]
        }
      ],
      "source": [
        "# Initial set up\n",
        "!pip install fastapi uvicorn nest_asyncio pyngrok requests\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install fireworks-ai"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "collapsed": true,
        "id": "yuhMZgMP9aUo",
        "outputId": "01671e86-311e-4790-9fc6-70c886860e28"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting fireworks-ai\n",
            "  Downloading fireworks_ai-0.19.19-py3-none-any.whl.metadata (2.4 kB)\n",
            "Requirement already satisfied: httpx in /usr/local/lib/python3.12/dist-packages (from fireworks-ai) (0.28.1)\n",
            "Collecting httpx-ws (from fireworks-ai)\n",
            "  Downloading httpx_ws-0.7.2-py3-none-any.whl.metadata (9.3 kB)\n",
            "Requirement already satisfied: httpx-sse in /usr/local/lib/python3.12/dist-packages (from fireworks-ai) (0.4.1)\n",
            "Requirement already satisfied: pydantic in /usr/local/lib/python3.12/dist-packages (from fireworks-ai) (2.11.7)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.12/dist-packages (from fireworks-ai) (11.3.0)\n",
            "Requirement already satisfied: openai in /usr/local/lib/python3.12/dist-packages (from fireworks-ai) (1.107.0)\n",
            "Requirement already satisfied: typing_extensions in /usr/local/lib/python3.12/dist-packages (from fireworks-ai) (4.15.0)\n",
            "Collecting mmh3>=4.1.0 (from fireworks-ai)\n",
            "  Downloading mmh3-5.2.0-cp312-cp312-manylinux1_x86_64.manylinux_2_28_x86_64.manylinux_2_5_x86_64.whl.metadata (14 kB)\n",
            "Collecting betterproto-fw>=2.0.3 (from betterproto-fw[compiler]>=2.0.3->fireworks-ai)\n",
            "  Downloading betterproto_fw-2.0.3-py3-none-any.whl.metadata (18 kB)\n",
            "Collecting asyncstdlib-fw>=3.13.2 (from fireworks-ai)\n",
            "  Downloading asyncstdlib_fw-3.13.2-py3-none-any.whl.metadata (5.0 kB)\n",
            "Requirement already satisfied: grpcio>=1.71.0 in /usr/local/lib/python3.12/dist-packages (from fireworks-ai) (1.74.0)\n",
            "Collecting protobuf==5.29.3 (from fireworks-ai)\n",
            "  Downloading protobuf-5.29.3-cp38-abi3-manylinux2014_x86_64.whl.metadata (592 bytes)\n",
            "Collecting rich>=14.0.0 (from fireworks-ai)\n",
            "  Downloading rich-14.1.0-py3-none-any.whl.metadata (18 kB)\n",
            "Requirement already satisfied: toml>=0.10.2 in /usr/local/lib/python3.12/dist-packages (from fireworks-ai) (0.10.2)\n",
            "Requirement already satisfied: aiohttp>=3.12.11 in /usr/local/lib/python3.12/dist-packages (from aiohttp[speedups]>=3.12.11->fireworks-ai) (3.12.15)\n",
            "Collecting attrs==23.2.0 (from fireworks-ai)\n",
            "  Downloading attrs-23.2.0-py3-none-any.whl.metadata (9.5 kB)\n",
            "Requirement already satisfied: googleapis-common-protos>=1.60.0 in /usr/local/lib/python3.12/dist-packages (from fireworks-ai) (1.70.0)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp>=3.12.11->aiohttp[speedups]>=3.12.11->fireworks-ai) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp>=3.12.11->aiohttp[speedups]>=3.12.11->fireworks-ai) (1.4.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.12/dist-packages (from aiohttp>=3.12.11->aiohttp[speedups]>=3.12.11->fireworks-ai) (1.7.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.12/dist-packages (from aiohttp>=3.12.11->aiohttp[speedups]>=3.12.11->fireworks-ai) (6.6.4)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp>=3.12.11->aiohttp[speedups]>=3.12.11->fireworks-ai) (0.3.2)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp>=3.12.11->aiohttp[speedups]>=3.12.11->fireworks-ai) (1.20.1)\n",
            "Collecting aiodns>=3.3.0 (from aiohttp[speedups]>=3.12.11->fireworks-ai)\n",
            "  Downloading aiodns-3.5.0-py3-none-any.whl.metadata (5.8 kB)\n",
            "Requirement already satisfied: Brotli in /usr/local/lib/python3.12/dist-packages (from aiohttp[speedups]>=3.12.11->fireworks-ai) (1.1.0)\n",
            "Requirement already satisfied: grpclib<0.5.0,>=0.4.1 in /usr/local/lib/python3.12/dist-packages (from betterproto-fw>=2.0.3->betterproto-fw[compiler]>=2.0.3->fireworks-ai) (0.4.8)\n",
            "Requirement already satisfied: python-dateutil<3.0.0,>=2.8.0 in /usr/local/lib/python3.12/dist-packages (from betterproto-fw>=2.0.3->betterproto-fw[compiler]>=2.0.3->fireworks-ai) (2.9.0.post0)\n",
            "Collecting ruff~=0.9.1 (from betterproto-fw[compiler]>=2.0.3->fireworks-ai)\n",
            "  Downloading ruff-0.9.10-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (25 kB)\n",
            "Requirement already satisfied: jinja2>=3.0.3 in /usr/local/lib/python3.12/dist-packages (from betterproto-fw[compiler]>=2.0.3->fireworks-ai) (3.1.6)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.12/dist-packages (from rich>=14.0.0->fireworks-ai) (4.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.12/dist-packages (from rich>=14.0.0->fireworks-ai) (2.19.2)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.12/dist-packages (from httpx->fireworks-ai) (4.10.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.12/dist-packages (from httpx->fireworks-ai) (2025.8.3)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx->fireworks-ai) (1.0.9)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.12/dist-packages (from httpx->fireworks-ai) (3.10)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx->fireworks-ai) (0.16.0)\n",
            "Collecting wsproto (from httpx-ws->fireworks-ai)\n",
            "  Downloading wsproto-1.2.0-py3-none-any.whl.metadata (5.6 kB)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.12/dist-packages (from openai->fireworks-ai) (1.9.0)\n",
            "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from openai->fireworks-ai) (0.10.0)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.12/dist-packages (from openai->fireworks-ai) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.12/dist-packages (from openai->fireworks-ai) (4.67.1)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic->fireworks-ai) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.12/dist-packages (from pydantic->fireworks-ai) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from pydantic->fireworks-ai) (0.4.1)\n",
            "Collecting pycares>=4.9.0 (from aiodns>=3.3.0->aiohttp[speedups]>=3.12.11->fireworks-ai)\n",
            "  Downloading pycares-4.11.0-cp312-cp312-manylinux_2_28_x86_64.whl.metadata (4.5 kB)\n",
            "Requirement already satisfied: h2<5,>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from grpclib<0.5.0,>=0.4.1->betterproto-fw>=2.0.3->betterproto-fw[compiler]>=2.0.3->fireworks-ai) (4.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2>=3.0.3->betterproto-fw[compiler]>=2.0.3->fireworks-ai) (3.0.2)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.12/dist-packages (from markdown-it-py>=2.2.0->rich>=14.0.0->fireworks-ai) (0.1.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil<3.0.0,>=2.8.0->betterproto-fw>=2.0.3->betterproto-fw[compiler]>=2.0.3->fireworks-ai) (1.17.0)\n",
            "Requirement already satisfied: hyperframe<7,>=6.1 in /usr/local/lib/python3.12/dist-packages (from h2<5,>=3.1.0->grpclib<0.5.0,>=0.4.1->betterproto-fw>=2.0.3->betterproto-fw[compiler]>=2.0.3->fireworks-ai) (6.1.0)\n",
            "Requirement already satisfied: hpack<5,>=4.1 in /usr/local/lib/python3.12/dist-packages (from h2<5,>=3.1.0->grpclib<0.5.0,>=0.4.1->betterproto-fw>=2.0.3->betterproto-fw[compiler]>=2.0.3->fireworks-ai) (4.1.0)\n",
            "Requirement already satisfied: cffi>=1.5.0 in /usr/local/lib/python3.12/dist-packages (from pycares>=4.9.0->aiodns>=3.3.0->aiohttp[speedups]>=3.12.11->fireworks-ai) (2.0.0)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.12/dist-packages (from cffi>=1.5.0->pycares>=4.9.0->aiodns>=3.3.0->aiohttp[speedups]>=3.12.11->fireworks-ai) (2.23)\n",
            "Downloading fireworks_ai-0.19.19-py3-none-any.whl (570 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m570.7/570.7 kB\u001b[0m \u001b[31m12.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading attrs-23.2.0-py3-none-any.whl (60 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m60.8/60.8 kB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading protobuf-5.29.3-cp38-abi3-manylinux2014_x86_64.whl (319 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m319.7/319.7 kB\u001b[0m \u001b[31m20.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading asyncstdlib_fw-3.13.2-py3-none-any.whl (44 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m44.9/44.9 kB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading betterproto_fw-2.0.3-py3-none-any.whl (105 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m105.1/105.1 kB\u001b[0m \u001b[31m7.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading mmh3-5.2.0-cp312-cp312-manylinux1_x86_64.manylinux_2_28_x86_64.manylinux_2_5_x86_64.whl (103 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m103.3/103.3 kB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading rich-14.1.0-py3-none-any.whl (243 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m243.4/243.4 kB\u001b[0m \u001b[31m13.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading httpx_ws-0.7.2-py3-none-any.whl (14 kB)\n",
            "Downloading aiodns-3.5.0-py3-none-any.whl (8.1 kB)\n",
            "Downloading ruff-0.9.10-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (11.3 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m11.3/11.3 MB\u001b[0m \u001b[31m92.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading wsproto-1.2.0-py3-none-any.whl (24 kB)\n",
            "Downloading pycares-4.11.0-cp312-cp312-manylinux_2_28_x86_64.whl (641 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m641.1/641.1 kB\u001b[0m \u001b[31m36.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: wsproto, ruff, protobuf, mmh3, attrs, asyncstdlib-fw, rich, pycares, httpx-ws, betterproto-fw, aiodns, fireworks-ai\n",
            "  Attempting uninstall: ruff\n",
            "    Found existing installation: ruff 0.12.12\n",
            "    Uninstalling ruff-0.12.12:\n",
            "      Successfully uninstalled ruff-0.12.12\n",
            "  Attempting uninstall: protobuf\n",
            "    Found existing installation: protobuf 5.29.5\n",
            "    Uninstalling protobuf-5.29.5:\n",
            "      Successfully uninstalled protobuf-5.29.5\n",
            "  Attempting uninstall: attrs\n",
            "    Found existing installation: attrs 25.3.0\n",
            "    Uninstalling attrs-25.3.0:\n",
            "      Successfully uninstalled attrs-25.3.0\n",
            "  Attempting uninstall: rich\n",
            "    Found existing installation: rich 13.9.4\n",
            "    Uninstalling rich-13.9.4:\n",
            "      Successfully uninstalled rich-13.9.4\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "bigframes 2.19.0 requires rich<14,>=12.4.4, but you have rich 14.1.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed aiodns-3.5.0 asyncstdlib-fw-3.13.2 attrs-23.2.0 betterproto-fw-2.0.3 fireworks-ai-0.19.19 httpx-ws-0.7.2 mmh3-5.2.0 protobuf-5.29.3 pycares-4.11.0 rich-14.1.0 ruff-0.9.10 wsproto-1.2.0\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "google"
                ]
              },
              "id": "a557d2a9947540c8bc71c2e7e0d220e8"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "FIREWORKS_API_KEY = \"\"\n",
        "FIREWORKS_SDK_DEBUG=True"
      ],
      "metadata": {
        "id": "BKHMkLsp9yrG"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# simple_eval.py\n",
        "import os, base64, glob, json\n",
        "from dotenv import load_dotenv\n",
        "from fireworks import LLM\n",
        "\n",
        "load_dotenv()\n",
        "API_KEY = os.getenv(\"FIREWORKS_API_KEY\")\n",
        "\n",
        "# ğŸ”¹ Fill in your Fireworks model IDs here\n",
        "MODELS = [\n",
        "  \"llama4-maverick-instruct-basic\",\n",
        "    \"lama4-scout-instruct-basic\",\n",
        "    \"qwen2p5-vl-32b-instruct\",\n",
        "]\n",
        "\n",
        "IMAGES = glob.glob(\"images/*.*\")[:10]  # pick your 10 images\n",
        "\n",
        "PROMPT = \"\"\"Extract the following fields from this ID document.\n",
        "Return only JSON with keys: name, dob (YYYY-MM-DD), issuing_country (ISO3),\n",
        "id_number, expiry_date (YYYY-MM-DD), address.\n",
        "If a field is missing, set it to null.\"\"\"\n",
        "\n",
        "def encode_image(path):\n",
        "    with open(path, \"rb\") as f:\n",
        "        return base64.b64encode(f.read()).decode(\"ascii\")\n",
        "\n",
        "def run():\n",
        "    for model in MODELS:\n",
        "        print(f\"\\n=== {model} ===\")\n",
        "        llm = LLM(model=model, api_key=API_KEY)\n",
        "\n",
        "        outputs = []\n",
        "        for img in IMAGES:\n",
        "            img_b64 = encode_image(img)\n",
        "            messages = [{\n",
        "                \"role\": \"user\",\n",
        "                \"content\": [\n",
        "                    {\"type\": \"image_url\", \"image_url\": {\"url\": f\"data:image/jpeg;base64,{img_b64}\"}},\n",
        "                    {\"type\": \"text\", \"text\": PROMPT},\n",
        "                ],\n",
        "            }]\n",
        "            resp = llm.chat.completions.create(messages=messages, max_tokens=500)\n",
        "            content = resp.choices[0].message.content\n",
        "            print(f\"{os.path.basename(img)} â†’ {content}\")\n",
        "            outputs.append({\"image\": img, \"output\": content})\n",
        "\n",
        "        with open(f\"results_{model.split('/')[-1]}.json\", \"w\") as f:\n",
        "            json.dump(outputs, f, indent=2)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    run()\n"
      ],
      "metadata": {
        "id": "oXbdgrDBTgQW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# score_colab.py (run this cell in Colab)\n",
        "\n",
        "import json, re, os\n",
        "from typing import List, Dict, Any\n",
        "\n",
        "# ---- Fields you care about (from your eval spec) ----\n",
        "FIELDS = [\"name\", \"dob\", \"issuing_country\", \"id_number\", \"expiry_date\", \"address\"]\n",
        "\n",
        "# ---------- Loaders & cleaners ----------\n",
        "def load_json(path: str) -> Any:\n",
        "    with open(path, \"r\", encoding=\"utf-8\") as f:\n",
        "        return json.load(f)\n",
        "\n",
        "def extract_json_block(text: str) -> Dict[str, Any]:\n",
        "    \"\"\"Pull the first {...} block out of a messy string like '```json { ... } ```'.\"\"\"\n",
        "    if not isinstance(text, str):\n",
        "        return {}\n",
        "    m = re.search(r\"\\{.*\\}\", text, flags=re.S)\n",
        "    if not m:\n",
        "        return {}\n",
        "    try:\n",
        "        return json.loads(m.group(0))\n",
        "    except Exception:\n",
        "        return {}\n",
        "\n",
        "def load_predictions_anyshape(path: str) -> List[Dict[str, Any]]:\n",
        "    \"\"\"\n",
        "    Supports two shapes:\n",
        "      1) Clean array of dicts (already JSON objects with the fields).\n",
        "      2) Array of {image, output: '```json { ... } ```'} from your model runs.\n",
        "    Returns a list of plain dicts with fields (no code fences, etc.).\n",
        "    \"\"\"\n",
        "    data = load_json(path)\n",
        "    if not data:\n",
        "        return []\n",
        "    # If it's the model-output style (has \"output\" strings), clean them:\n",
        "    if isinstance(data[0], dict) and \"output\" in data[0] and isinstance(data[0][\"output\"], str):\n",
        "        cleaned = []\n",
        "        for rec in data:\n",
        "            obj = extract_json_block(rec[\"output\"])\n",
        "            # Keep image name for human-friendly tables (optional)\n",
        "            if \"image\" in rec:\n",
        "                obj[\"image\"] = rec[\"image\"]\n",
        "            cleaned.append(obj)\n",
        "        return cleaned\n",
        "    # Otherwise assume it's already an array of plain dicts\n",
        "    return data\n",
        "\n",
        "# ---------- Normalization (simple & friendly) ----------\n",
        "def norm(v):\n",
        "    if v is None:\n",
        "        return None\n",
        "    return str(v).strip().upper()\n",
        "\n",
        "def normalize_record(rec: Dict[str, Any]) -> Dict[str, Any]:\n",
        "    return {f: norm(rec.get(f)) for f in FIELDS}\n",
        "\n",
        "# ---------- Scoring ----------\n",
        "def compare_by_index(gt: List[Dict[str, Any]], pr: List[Dict[str, Any]]):\n",
        "    \"\"\"\n",
        "    Compares record i in eval with record i in predictions.\n",
        "    Returns per-field accuracy, ALL_FIELDS_EXACT, and side-by-side rows.\n",
        "    \"\"\"\n",
        "    # Normalize once\n",
        "    gt_norm = [normalize_record(r) for r in gt]\n",
        "    pr_norm = [normalize_record(r) for r in pr]\n",
        "\n",
        "    n = min(len(gt_norm), len(pr_norm))\n",
        "    totals = {f: 0 for f in FIELDS}\n",
        "    correct = {f: 0 for f in FIELDS}\n",
        "    all_exact = 0\n",
        "    side_by_side_rows = []  # for human inspection\n",
        "\n",
        "    for i in range(n):\n",
        "        g = gt_norm[i]\n",
        "        p = pr_norm[i]\n",
        "        row_all_ok = True\n",
        "        row_display = {\"#\": i+1}\n",
        "        for f in FIELDS:\n",
        "            gv, pv = g.get(f), p.get(f)\n",
        "            row_display[f] = f\"{gv or 'âˆ…'}  /  {pv or 'âˆ…'}\"\n",
        "            totals[f] += 1\n",
        "            if gv == pv:\n",
        "                correct[f] += 1\n",
        "            else:\n",
        "                row_all_ok = False\n",
        "        if row_all_ok:\n",
        "            all_exact += 1\n",
        "        side_by_side_rows.append(row_display)\n",
        "\n",
        "    acc = {f: (100.0 * correct[f] / totals[f] if totals[f] else 0.0) for f in FIELDS}\n",
        "    acc[\"ALL_FIELDS_EXACT\"] = 100.0 * all_exact / n if n else 0.0\n",
        "    return acc, side_by_side_rows, n\n",
        "\n",
        "def print_accuracy_table(model_label: str, acc: Dict[str, float], n_docs: int):\n",
        "    print(f\"\\n=== {model_label} ===\")\n",
        "    print(f\"Docs compared: {n_docs}\")\n",
        "    for f in FIELDS:\n",
        "        print(f\"{f:16s}: {acc[f]:5.1f}%\")\n",
        "    print(f\"{'ALL_FIELDS_EXACT':16s}: {acc['ALL_FIELDS_EXACT']:5.1f}%\")\n",
        "\n",
        "def print_side_by_side(model_label: str, rows: List[Dict[str, str]], max_rows=None):\n",
        "    print(f\"\\n-- {model_label}: Eval vs Model (eval  /  model) --\")\n",
        "    header = [\"#\"] + FIELDS\n",
        "    print(\" | \".join(h.upper() for h in header))\n",
        "    print(\"-\" * 110)\n",
        "    count = 0\n",
        "    for r in rows:\n",
        "        if max_rows is not None and count >= max_rows:\n",
        "            break\n",
        "        cells = [str(r['#'])] + [r[f] for f in FIELDS]\n",
        "        print(\" | \".join(cells))\n",
        "        count += 1\n",
        "\n",
        "# ---------- Main (edit your paths here) ----------\n",
        "eval_path = \"/content/eval.json\"\n",
        "model_paths = [\n",
        "    \"/content/results_llama4-maverick-instruct-basic.json\",\n",
        "    \"/content/results_llama4-scout-instruct-basic.json\",\n",
        "    \"/content/results_qwen2p5-vl-32b-instruct.json\",\n",
        "]\n",
        "\n",
        "# Load eval (already a clean array of dicts)\n",
        "eval_data = load_json(eval_path)\n",
        "\n",
        "# Score each model\n",
        "best_label, best_score = None, -1.0\n",
        "for mp in model_paths:\n",
        "    preds = load_predictions_anyshape(mp)\n",
        "    acc, rows, n_docs = compare_by_index(eval_data, preds)\n",
        "\n",
        "    label = os.path.basename(mp)\n",
        "    print_accuracy_table(label, acc, n_docs)\n",
        "    # Side-by-side for quick judgment (print all docs)\n",
        "    print_side_by_side(label, rows)\n",
        "\n",
        "    if acc[\"ALL_FIELDS_EXACT\"] > best_score:\n",
        "        best_score = acc[\"ALL_FIELDS_EXACT\"]\n",
        "        best_label = label\n",
        "\n",
        "print(f\"\\n>>> BEST MODEL: {best_label}  ({best_score:.1f}% ALL_FIELDS_EXACT)\")\n"
      ],
      "metadata": {
        "id": "tVq9fQTWcTef",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "00b61306-b616-4711-c362-8320e796e9c6"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "=== results_llama4-maverick-instruct-basic.json ===\n",
            "Docs compared: 9\n",
            "name            :  55.6%\n",
            "dob             : 100.0%\n",
            "issuing_country : 100.0%\n",
            "id_number       :  66.7%\n",
            "expiry_date     :  66.7%\n",
            "address         :  44.4%\n",
            "ALL_FIELDS_EXACT:  11.1%\n",
            "\n",
            "-- results_llama4-maverick-instruct-basic.json: Eval vs Model (eval  /  model) --\n",
            "# | NAME | DOB | ISSUING_COUNTRY | ID_NUMBER | EXPIRY_DATE | ADDRESS\n",
            "--------------------------------------------------------------------------------------------------------------\n",
            "1 | IMA CARDHLDER  /  IMA CARDHOLDER | 1977-08-31  /  1977-08-31 | USA  /  USA | 000123456789  /  11234568 | 2024-08-31  /  2014-08-31 | 2570 24TH STREET ANYTOWN, CA 95818  /  2570 24TH STREET ANYTOWN, CA 95818\n",
            "2 | SAMPLE JAICE ANN  /  JANICE ANN SAMPLE | 2005-01-07  /  2005-01-07 | USA  /  USA | âˆ…  /  99999999 | 2026-01-08  /  2026-01-08 | 123 MAIN STREET APT1 HARRISBURG PA 17101-0000  /  123 MAIN STREET APT.1 HARRISBURG, PA 17101-0000\n",
            "3 | JOHN Q PUBLIC  /  JOHN Q PUBLIC | 1952-05-28  /  1952-05-28 | USA  /  USA | 000123456789  /  123456789 | 2029-05-28  /  2029-05-28 | 1234 YOUR STREET, NC 99999-1234  /  1234 YOUR STREET, YOUR CITY, NC 99999-1234\n",
            "4 | JOHN SAMPLE  /  JOHN SAMPLE | 1967-01-12  /  1967-01-12 | USA  /  USA | S000123456789  /  S000123456789 | 2028-01-12  /  2028-01-12 | 123 NORTH MAIN ST LANSING, MI 48918-1234  /  123 NORTH MAIN ST, LANSING, MI 48918-1234\n",
            "5 | ROBERT JASON BLUM  /  ROBERT JASON BLUM | 1980-05-14  /  1980-05-14 | USA  /  USA | D83772430  /  D83772430 | 2024-05-14  /  2024-05-14 | 2033 ROCK BEACH DR. CLEARLAKE, AZ, 85129  /  2033 ROCK BEACH DR. CLEARLAKE, AZ 85129\n",
            "6 | JOHN DOE  /  JOHN DOE | 1996-03-15  /  1996-03-15 | USA  /  USA | 963545637  /  963545637 | 2017-04-12  /  2027-04-14 | âˆ…  /  âˆ…\n",
            "7 | BENJAMIN FRANKLIN  /  BENJAMIN FRANKLIN | 1706-01-17  /  1706-01-17 | USA  /  USA | 575034801  /  575034801 | 2028-01-15  /  2028-01-15 | âˆ…  /  âˆ…\n",
            "8 | RAM RAHUL GUPTA  /  RAHUL RAM GUPTA | 1974-01-22  /  1974-01-22 | USA  /  USA | 31195855  /  31195855 | 2014-09-17  /  2014-09-17 | âˆ…  /  âˆ…\n",
            "9 | HAPPY TRAVELLER  /  TRAVELER HAPPY | 1965-02-05  /  1965-02-05 | USA  /  USA | E00009349  /  E00009349 | 2020-07-09  /  2030-07-09 | âˆ…  /  WASHINGTON, D.C., U.S.A.\n",
            "\n",
            "=== results_llama4-scout-instruct-basic.json ===\n",
            "Docs compared: 9\n",
            "name            :  55.6%\n",
            "dob             :  77.8%\n",
            "issuing_country : 100.0%\n",
            "id_number       :  66.7%\n",
            "expiry_date     :  66.7%\n",
            "address         :  44.4%\n",
            "ALL_FIELDS_EXACT:  11.1%\n",
            "\n",
            "-- results_llama4-scout-instruct-basic.json: Eval vs Model (eval  /  model) --\n",
            "# | NAME | DOB | ISSUING_COUNTRY | ID_NUMBER | EXPIRY_DATE | ADDRESS\n",
            "--------------------------------------------------------------------------------------------------------------\n",
            "1 | IMA CARDHLDER  /  IMA CARDHOLDER | 1977-08-31  /  1977-08-31 | USA  /  USA | 000123456789  /  11234568 | 2024-08-31  /  2014-08-31 | 2570 24TH STREET ANYTOWN, CA 95818  /  2570 24TH STREET, ANYTOWN, CA 95818\n",
            "2 | SAMPLE JAICE ANN  /  JANICE SAMPLE | 2005-01-07  /  2005-01-07 | USA  /  USA | âˆ…  /  99999999 | 2026-01-08  /  2026-01-08 | 123 MAIN STREET APT1 HARRISBURG PA 17101-0000  /  123 MAIN STREET, APT. 1, HARRISBURG, PA 17101-0000\n",
            "3 | JOHN Q PUBLIC  /  JOHN Q PUBLIC | 1952-05-28  /  âˆ… | USA  /  USA | 000123456789  /  0000123456789 | 2029-05-28  /  2029-05-28 | 1234 YOUR STREET, NC 99999-1234  /  1234 YOUR STREET, JOHN Q, NC 99999-1234\n",
            "4 | JOHN SAMPLE  /  JOHN SAMPLE | 1967-01-12  /  1967-01-12 | USA  /  USA | S000123456789  /  S000123456789 | 2028-01-12  /  2028-01-12 | 123 NORTH MAIN ST LANSING, MI 48918-1234  /  123 NORTH MAIN ST, LANSING, MI 48918-1234\n",
            "5 | ROBERT JASON BLUM  /  ROBERT JASON BLUM | 1980-05-14  /  1980-05-14 | USA  /  USA | D83772430  /  D83772430 | 2024-05-14  /  2024-05-14 | 2033 ROCK BEACH DR. CLEARLAKE, AZ, 85129  /  2033 ROCK BEACH DR. CLEARLAKE, AZ 85129\n",
            "6 | JOHN DOE  /  JOHN DOE | 1996-03-15  /  1996-03-15 | USA  /  USA | 963545637  /  963545637 | 2017-04-12  /  2027-04-14 | âˆ…  /  âˆ…\n",
            "7 | BENJAMIN FRANKLIN  /  BENJAMIN FRANKLIN | 1706-01-17  /  1706-01-17 | USA  /  USA | 575034801  /  575034801 | 2028-01-15  /  2028-01-15 | âˆ…  /  âˆ…\n",
            "8 | RAM RAHUL GUPTA  /  RAHUL RAM GUPTA | 1974-01-22  /  1974-01-22 | USA  /  USA | 31195855  /  31195855 | 2014-09-17  /  2014-09-17 | âˆ…  /  âˆ…\n",
            "9 | HAPPY TRAVELLER  /  HAPPY TRAVELER | 1965-02-05  /  1945-02-05 | USA  /  USA | E00009349  /  E00009349 | 2020-07-09  /  2030-07-09 | âˆ…  /  âˆ…\n",
            "\n",
            "=== results_qwen2p5-vl-32b-instruct.json ===\n",
            "Docs compared: 9\n",
            "name            :  55.6%\n",
            "dob             : 100.0%\n",
            "issuing_country : 100.0%\n",
            "id_number       :  77.8%\n",
            "expiry_date     :  55.6%\n",
            "address         :   0.0%\n",
            "ALL_FIELDS_EXACT:   0.0%\n",
            "\n",
            "-- results_qwen2p5-vl-32b-instruct.json: Eval vs Model (eval  /  model) --\n",
            "# | NAME | DOB | ISSUING_COUNTRY | ID_NUMBER | EXPIRY_DATE | ADDRESS\n",
            "--------------------------------------------------------------------------------------------------------------\n",
            "1 | IMA CARDHLDER  /  IMA CARDHOLDER | 1977-08-31  /  1977-08-31 | USA  /  USA | 000123456789  /  I1234568 | 2024-08-31  /  2014-08-31 | 2570 24TH STREET ANYTOWN, CA 95818  /  2570 24TH STREET, ANYTOWN, CA 95818\n",
            "2 | SAMPLE JAICE ANN  /  JANICE SAMPLE | 2005-01-07  /  2005-01-07 | USA  /  USA | âˆ…  /  99999999 | 2026-01-08  /  2026-01-08 | 123 MAIN STREET APT1 HARRISBURG PA 17101-0000  /  123 MAIN STREET, APT. 1, HARRISBURG, PA 17101-0000\n",
            "3 | JOHN Q PUBLIC  /  JOHN Q PUBLIC | 1952-05-28  /  1952-05-28 | USA  /  USA | 000123456789  /  000123456789 | 2029-05-28  /  2029-05-10 | 1234 YOUR STREET, NC 99999-1234  /  1234 YOUR STREET YOUR CITY, NC 99999-1234\n",
            "4 | JOHN SAMPLE  /  JOHN SAMPLE | 1967-01-12  /  1967-01-12 | USA  /  USA | S000123456789  /  S000123456789 | 2028-01-12  /  2028-01-12 | 123 NORTH MAIN ST LANSING, MI 48918-1234  /  123 NORTH MAIN ST, LANSING, MI 48918-1234\n",
            "5 | ROBERT JASON BLUM  /  ROBERT JASON BLUM | 1980-05-14  /  1980-05-14 | USA  /  USA | D83772430  /  D83772430 | 2024-05-14  /  2024-05-14 | 2033 ROCK BEACH DR. CLEARLAKE, AZ, 85129  /  2033 ROCK BEACH DR. CLEARLAKE, AZ 85129\n",
            "6 | JOHN DOE  /  JOHN DOE | 1996-03-15  /  1996-03-15 | USA  /  USA | 963545637  /  963545637 | 2017-04-12  /  2027-04-14 | âˆ…  /  CALIFORNIA, U.S.A\n",
            "7 | BENJAMIN FRANKLIN  /  BENJAMIN FRANKLIN | 1706-01-17  /  1706-01-17 | USA  /  USA | 575034801  /  575034801 | 2028-01-15  /  2028-01-15 | âˆ…  /  PROVINCE OF MASSACHUSETTS BAY, USA\n",
            "8 | RAM RAHUL GUPTA  /  RAHUL RAM GUPTA | 1974-01-22  /  1974-01-22 | USA  /  USA | 31195855  /  31195855 | 2014-09-17  /  2014-09-17 | âˆ…  /  MUMBAI, INDIA\n",
            "9 | HAPPY TRAVELLER  /  HAPPY TRAVELER | 1965-02-05  /  1965-02-05 | USA  /  USA | E00009349  /  E00009349 | 2020-07-09  /  2030-07-09 | âˆ…  /  WASHINGTON, D.C., USA\n",
            "\n",
            ">>> BEST MODEL: results_llama4-maverick-instruct-basic.json  (11.1% ALL_FIELDS_EXACT)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "APqk1JP9ciWq"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}